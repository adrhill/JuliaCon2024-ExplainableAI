---
title: "What's new with Explainable AI in Julia?"
title-slide-attributes:
  data-background-image: /img/qr/qrbackground.png
  data-background-size: contain
author:
  - name: Adrian Hill
    orcid: 0009-0009-5977-301X
    email: hill@tu-berlin.de
    affiliation: 
      - name: Technische UniversitÃ¤t Berlin
      - department: Machine Learning Group
date: "2024-07-11"
bibliography: library.bib
engine: julia
format:
  revealjs:
    theme: [default, custom.scss]
    footer: "[github.com/Julia-XAI](http://github.com/Julia-XAI)"
    slide-number: true
    overview: true
    code-line-numbers: false
execute:
    echo: true
    freeze: auto
---

# Introduction

## ExplainableAI.jl to Julia-XAI

::: {.callout-note}
## What kind of explanations?

Post-hoc, local input-space explanations of black-box models:
 
> "Which part of the input is responsible for the model's output?"
:::

- **JuliaCon 2022:** ExplainableAI.jl
- **JuliaCon 2024:** Julia-XAI organization

## Motivating example

![](img/castle.jpg){width=300px;}
```{julia}
#| echo: false
using Images
using ImageNetDataset

# Prepare data
img = load("img/castle.jpg")
tfm = CenterCropNormalize()
input = reshape(transform(tfm, "img/castle.jpg"), 224, 224, 3, :);
```

```{julia}
using Flux, Metalhead
model = VGG(19; pretrain=true).layers
testmode!(model)

prediction = model(input)
class = argmax(prediction) # class 484: castle
```

Pretrained model predicts class "castle". **But why?**

## Methods {.smaller}

- [ExplainableAI.jl](https://github.com/Julia-XAI/ExplainableAI.jl) â€“ applicable on *any* differentiable classifier
  - `Gradient`
  - `InputTimesGradient` 
  - `SmoothGrad` @smilkov2017smoothgrad
  - `IntegratedGradients` @sundararajan2017axiomatic
  - ðŸ†• `GradCAM` @selvaraju2017grad
- [RelevancePropagation.jl](https://github.com/Julia-XAI/RelevancePropagation.jl) â€“ applicable on Flux.jl classifiers
  - `LRP` @bach2015pixel
    - ðŸ†• support for ResNets
    - ðŸ†• support for Transformers @ali2022xai, @achtibat2024attnlrp
  - ðŸ†• `CRP` @achtibat23crp

## Methods: input sensitivity

```{julia}
using ExplainableAI
using VisionHeatmaps

analyzer = Gradient(model)
expl = analyze(input, analyzer)
heatmap(expl)
```

## Methods: GradCAM

```{julia}
using ExplainableAI
using VisionHeatmaps

analyzer = GradCAM(model[1], model[2])
expl = analyze(input, analyzer)
heatmap_overlay(expl, img)
```

## Methods: LRP

```{julia}
using RelevancePropagation
using VisionHeatmaps

analyzer = LRP(model, EpsilonPlusFlat())
explanation = analyze(input, analyzer)
heatmap(explanation)
```

## The Julia-XAI ecosystem

::: {.center-img}
![](img/org.png)
:::

## VisionHeatmaps.jl {.smaller}

```{julia}
heatmap(explanation)  
``` 

```{julia}
heatmap(explanation; colorscheme=:inferno, rangescale=:extrema)
``` 

::: {.notes}
New features:
- normalization over batches
- heatmap overlays
:::

## TextHeatmaps.jl {.smaller}

Visualize explanations on **language models**

```{julia}
using TextHeatmaps

words = split("I loved the concert but not the opening act")
val = [0.1, 2.5, 0.0, 0.3, -0.6, -1.4, 0.0, 0.1, -0.1]
TextHeatmaps.heatmap(val, words)
``` 

```{julia}
TextHeatmaps.heatmap(val, words; rangescale=:extrema)
```

```{julia}
using ColorSchemes
TextHeatmaps.heatmap(val, words; colorscheme=:inferno)
```

## XAIBase.jl

**Interface definition:**

1. method has to be a subtype of `AbstractXAIMethod`
2. method has to return `Explanation`

::: {.callout-note}
# Benefits
- automatically compute heatmaps using [VisionHeatmaps.jl](https://julia-xai.github.io/XAIDocs/VisionHeatmaps/stable/)
and [TextHeatmaps.jl](https://julia-xai.github.io/XAIDocs/TextHeatmaps/stable/)
- dependency free
- perfect for package extensions!
:::

## References

::: {#refs}
:::
